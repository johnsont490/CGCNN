{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import argparse\n",
    "import sys\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Reshape, BatchNormalization\n",
    "from keras.layers import (\n",
    "    Conv1D,\n",
    "    GlobalAveragePooling1D,\n",
    "    MaxPooling1D,\n",
    "    GlobalAveragePooling1D,\n",
    "    Reshape,\n",
    "    AveragePooling1D,\n",
    "    Flatten,\n",
    "    Concatenate,\n",
    ")\n",
    "from keras import backend\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"ML framework\")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--data_dir\",\n",
    "    type=str,\n",
    "    help=\"path to file containing DOS and targets\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--run_mode\",\n",
    "    default=0,\n",
    "    type=int,\n",
    "    help=\"run regular (0) or 5-fold CV (1) (default: 0)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--split_ratio\", default=0.2, type=float, help=\"train/test ratio (default:0.2)\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--epochs\", default=60, type=int, help=\"number of total epochs to run (default:60)\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", default=32, type=int, help=\"batch size (default:32)\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--orbitals\", default=9, type=int, help=\"number of orbitals\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\",\n",
    "    default=0,\n",
    "    type=int,\n",
    "    help=\"seed for data split(epochs), 0=random (default:0)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_model\",\n",
    "    default=0,\n",
    "    type=int,\n",
    "    help=\"save model (1) or not (0) (default: 0)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--load_model\",\n",
    "    default=0,\n",
    "    type=int,\n",
    "    help=\"load pre-trained model (0)or not (1)? (default: 0)\",\n",
    ")\n",
    "args = parser.parse_args(sys.argv[1:])\n",
    "def load_data(args.data_dir): \n",
    "    initial_site_dos = df['initial site dos']\n",
    "    final_site_dos = df['final site dos']\n",
    "    def convert_string(input_str):\n",
    "        pattern = r\"<(.*?): (.*?): \\[(.*?)\\]\"\n",
    "        matches = re.findall(pattern, input_str)\n",
    "\n",
    "        result = {}\n",
    "        for match in matches:\n",
    "            if len(match) >= 3:\n",
    "                orbital = match[0].split(': ')[1] if ': ' in match[0] else match[0]  \n",
    "                spin = match[1].split(': ')[1] if ': ' in match[1] else match[1]   \n",
    "                values = [float(val) for val in match[2].split(',')]\n",
    "                if orbital not in result:\n",
    "                    result[orbital] = {}\n",
    "                result[orbital][spin] = values\n",
    "\n",
    "        final_result = {}\n",
    "        for orbital, values in result.items():\n",
    "            if orbital not in final_result:\n",
    "                final_result[orbital] = {}\n",
    "            final_result[orbital] = values\n",
    "\n",
    "        return final_result\n",
    "\n",
    "    initial_site_dos = [convert_string(string) for string in initial_site_dos]\n",
    "    final_site_dos = [convert_string(string) for string in final_site_dos]\n",
    "    max_length = max(len(row) for row in initial_site_dos)\n",
    "    pra = []\n",
    "    for row in initial_site_dos:\n",
    "        pr = row + [0] * (max_length - len(row))\n",
    "        pra.append(pr)\n",
    "    initial_dos_arr = pra\n",
    "    max_length = max(len(row) for row in final_site_dos)\n",
    "    pra = []\n",
    "    for row in final_site_dos:\n",
    "        pr = row + [0] * (max_length - len(row))\n",
    "        pra.append(pr)\n",
    "    final_dos_arr = pra\n",
    "    final_dos_arr = np.array(final_dos_arr)\n",
    "    final_dos_arr.shape\n",
    "\n",
    "    dos_training = np.concatenate(initial_dos_arr,final_dos_arr)\n",
    "    VFE_tr = np.concatenate(initial_VFE,final_VFE)\n",
    "    \n",
    "def preprocess_data(X_dos, Y_vfedata):\n",
    "    X_initial_train, X_initial_test, Y_initial_train, Y_initial_test = train_test_split(\n",
    "        X_dos[0], Y_vfedata[0], test_size=0.2, random_state=42\n",
    "    )\n",
    "    X_final_train, X_final_test, Y_final_train, Y_final_test = train_test_split(\n",
    "        X_dos[1], Y_vfedata[1], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_initial_train = scaler.fit_transform(X_initial_train.reshape(-1, X_initial_train.shape[2])).reshape(X_initial_train.shape)\n",
    "    X_initial_test = scaler.transform(X_initial_test.reshape(-1, X_initial_test.shape[2])).reshape(X_initial_test.shape)\n",
    "    X_final_train = scaler.fit_transform(X_final_train.reshape(-1, X_final_train.shape[2])).reshape(X_final_train.shape)\n",
    "    X_final_test = scaler.transform(X_final_test.reshape(-1, X_final_test.shape[2])).reshape(X_final_test.shape)\n",
    "\n",
    "    return (\n",
    "        X_initial_train, X_initial_test, Y_initial_train, Y_initial_test,\n",
    "        X_final_train, X_final_test, Y_final_train, Y_final_test\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "\n",
    "    X_dos, Y_vfedata = load_data()\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = preprocess_data(X_dos, Y_vfedata)\n",
    "\n",
    "    model = build_model()\n",
    "    train_model(model, X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "def build_model():\n",
    "    input_initial_dos = Input(shape=(1573, 5447))\n",
    "    input_final_dos = Input(shape=(1573, 5447))\n",
    "    shared_conv = dos_featurizer()\n",
    "    initial_features = shared_conv(input_initial_dos)\n",
    "    final_features = shared_conv(input_final_dos)\n",
    "    merged_features = Concatenate(axis=-1)([initial_features, final_features])\n",
    "    merged_features = Flatten()(merged_features)\n",
    "    merged_features = Dropout(0.2)(merged_features)\n",
    "    output_initial = Dense(1, activation='linear', name='initial_energy')(merged_features)\n",
    "    output_final = Dense(1, activation='linear', name='final_energy')(merged_features)\n",
    "    model = Model(inputs=[input_initial_dos, input_final_dos], outputs=[output_initial, output_final])\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, Y_train, X_test, Y_test):\n",
    "    model.fit(X_train, [Y_train, Y_train], validation_data=(X_test, [Y_test, Y_test]), epochs=10, batch_size=32)\n",
    "    \n",
    "def dos_featurizer():\n",
    "    input_dos = Input(shape=(1573, 5447))\n",
    "    x = input_dos\n",
    "    x = Conv1D(filters=32, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = AveragePooling1D(pool_size=2, strides=2, padding=\"same\")(x)\n",
    "    x = Conv1D(filters=64, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = AveragePooling1D(pool_size=2, strides=2, padding=\"same\")(x)\n",
    "    x = Conv1D(filters=128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = AveragePooling1D(pool_size=2, strides=2, padding=\"same\")(x)\n",
    "    output = Flatten()(x)\n",
    "    model = Model(inputs=input_dos, outputs=output)\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
